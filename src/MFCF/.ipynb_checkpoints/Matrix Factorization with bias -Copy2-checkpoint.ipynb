{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "                 learning_rate = 0.5, max_iter = 1000, print_every = 100):\n",
    "        self.Y      = Y    # represents the utility matrix \n",
    "        self.user = Y[:, 0]\n",
    "        self.item = Y[:, 1]\n",
    "        self.rating = Y[:, 2]\n",
    "        self.K      = K    # \n",
    "        self.lam    = lam  # regularization parameter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter      = max_iter # maximum number of iterations \n",
    "        self.print_every   = print_every # print loss+ RMSE on training data after each ? iters \n",
    "        self.n_users       = int(np.max(self.user)) + 1 \n",
    "        self.n_items       = int(np.max(self.item)) + 1\n",
    "        self.n_ratings     = Y.shape[0] # number of known ratings\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit \n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit \n",
    "        self.b = np.random.randn(self.n_items) # item biases\n",
    "        self.d = np.random.randn(self.n_users) # user biases\n",
    "        self.mu = np.mean(self.rating)\n",
    "\n",
    "    def loss(self):\n",
    "        L = 0 \n",
    "        for n in range(self.n_ratings):\n",
    "            # user_id, item_id, rating\n",
    "            u, i, rating = self.user[n], self.item[n], self.rating[n]\n",
    "            pred_rating = self.X[i].dot(self.W[:, u]) + self.b[i] + self.d[u] + self.mu \n",
    "            L += 0.5*(pred_rating - rating)**2 + .5*self.lam*(self.b[i]*2 + \n",
    "                    self.d[u]*2 + np.sum(self.X[i]**2) + np.sum(self.W[:, u]**2))\n",
    "        \n",
    "        return L/self.n_ratings\n",
    "\n",
    "    def updateXb(self):\n",
    "        for m in range(self.n_items):\n",
    "            # get all users who rated item m and get the corresponding ratings\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m \n",
    "            user_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            for i in range(30):\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.b[m] + dm  - ratings \n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.learning_rate*grad_xm.reshape(-1)\n",
    "                self.b[m] -= self.learning_rate*grad_bm\n",
    "    \n",
    "    def updateWd(self): # and d \n",
    "        for n in range(self.n_users):\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:,0] == n)[0] # row indices of items rated by user n \n",
    "            item_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30):\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\n",
    "                self.d[n]    -= self.learning_rate*grad_dn\n",
    "    \n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            # mix data \n",
    "            idx = np.random.permutation(self.n_ratings)\n",
    "            for n in idx:\n",
    "                u, i, rating = self.user[n], self.item[n], self.rating[n]\n",
    "                pred_rating = self.X[i].dot(self.W[:, u]) + self.b[i] + self.d[u] + self.mu \n",
    "                error = pred_rating - rating \n",
    "                self.b[i] -= self.learning_rate*(error + self.lam*self.b[i])\n",
    "                self.d[u] -= self.learning_rate*(error + self.lam*self.d[u])\n",
    "                self.X[i] -= self.learning_rate*(error*self.W[:, u] + self.lam*self.X[i])\n",
    "                self.W[:, u] -= self.learning_rate*(error*self.X[i] + self.lam*self.W[:, u])\n",
    "\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y)\n",
    "                print('iter = %d, loss = %.4f, RMSE train = %.4f'%(it + 1, self.loss(), rmse_train))\n",
    "    \n",
    "    def pred(self, u, i):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i \n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u] + self.mu# + bias\n",
    "        return max(0, min(5, pred)) # pred should be between 0 and 5 in MoviesLen \n",
    "    \n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test \n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "        \n",
    "# r_cols = ['user_id', 'item_id', 'rating']\n",
    "# ratings = pd.read_csv('ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "# Y_data = ratings.as_matrix()\n",
    "\n",
    "# rs = MF(Y_data, K = 3, max_iter = 1000, print_every = 100, lam = 0.1)\n",
    "# rs.fit()\n",
    "# rs.pred(6, 1)\n",
    "# print(rs.evaluate_RMSE(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Áp dụng lên MovieLens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 1, loss = 13.3134, RMSE train = 2.4421\n",
      "iter = 2, loss = 8.2733, RMSE train = 2.2708\n",
      "iter = 3, loss = 5.7890, RMSE train = 2.1119\n",
      "iter = 4, loss = 4.3564, RMSE train = 1.9720\n",
      "iter = 5, loss = 3.4453, RMSE train = 1.8514\n",
      "iter = 6, loss = 2.8261, RMSE train = 1.7475\n",
      "iter = 7, loss = 2.3839, RMSE train = 1.6571\n",
      "iter = 8, loss = 2.0560, RMSE train = 1.5778\n",
      "iter = 9, loss = 1.8055, RMSE train = 1.5079\n",
      "iter = 10, loss = 1.6093, RMSE train = 1.4455\n",
      "iter = 11, loss = 1.4526, RMSE train = 1.3900\n",
      "iter = 12, loss = 1.3252, RMSE train = 1.3403\n",
      "iter = 13, loss = 1.2202, RMSE train = 1.2955\n",
      "iter = 14, loss = 1.1324, RMSE train = 1.2551\n",
      "iter = 15, loss = 1.0582, RMSE train = 1.2184\n",
      "iter = 16, loss = 0.9950, RMSE train = 1.1849\n",
      "iter = 17, loss = 0.9405, RMSE train = 1.1544\n",
      "iter = 18, loss = 0.8932, RMSE train = 1.1266\n",
      "iter = 19, loss = 0.8519, RMSE train = 1.1010\n",
      "iter = 20, loss = 0.8155, RMSE train = 1.0776\n",
      "\n",
      "Matrix Factorization CF, RMSE = 1.9278\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 100, lam = .01, print_every = 1, learning_rate = 0.001, max_iter = 20)\n",
    "rs.fit()\n",
    "# evaluate on test data\n",
    "RMSE = rs.evaluate_RMSE(rate_test)\n",
    "print('\\nMatrix Factorization CF, RMSE = %.4f' %RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.X.shape\n",
    "rs.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
